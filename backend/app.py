import os
import io
import random
import logging
from datetime import datetime
import uuid

import numpy as np
import torch
import librosa
import soundfile as sf
import ffmpeg

from fastapi import FastAPI, File, UploadFile, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
import uvicorn
from dotenv import load_dotenv
from bson import ObjectId

from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from reportlab.lib.units import cm

# ================= LOAD ENV =================
load_dotenv()

# ================= PROJECT IMPORTS =================
from database import history_collection
from auth import router as auth_router, get_current_user
from contact import router as contact_router   # ✅ CONTACT ROUTER
from model_loader import load_model_robust

# ================= LOGGING =================
logger = logging.getLogger("stutter-api")
logging.basicConfig(level=logging.INFO)

# ================= MODEL LOAD =================
MODEL_PATH = os.environ.get("MODEL_PATH", "./models/model_epoch10.pth")
DEVICE = os.environ.get("DEVICE", "cpu")

logger.info(f"Loading model from: {MODEL_PATH}")
model = load_model_robust(MODEL_PATH, device=DEVICE)

if model is None:
    logger.warning("No model loaded, using fallback logic")
else:
    logger.info("MODEL LOADED SUCCESSFULLY")

# ================= FASTAPI APP =================
app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # frontend: http://127.0.0.1:3000
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ================= ROUTERS =================
app.include_router(auth_router, prefix="/auth", tags=["auth"])
app.include_router(contact_router, tags=["contact"])   # ✅ THIS WAS REQUIRED

# ================= AUDIO CONFIG =================
SR = 16000
TARGET_LEN = 24000
N_MELS = 64
N_FFT = 1024
HOP_LEN = 256

# ================= AUDIO DECODER =================
def audio_bytes_to_np(raw: bytes):
    if not raw or len(raw) < 10:
        raise HTTPException(status_code=400, detail="Empty audio")

    try:
        y, sr = sf.read(io.BytesIO(raw), dtype="float32")
        if y.ndim > 1:
            y = np.mean(y, axis=1)
        if sr != SR:
            y = librosa.resample(y, sr, SR)
        return y
    except Exception:
        pass

    try:
        out, _ = (
            ffmpeg.input("pipe:")
            .output("pipe:", format="wav", acodec="pcm_s16le", ac=1, ar=str(SR))
            .run(input=raw, capture_stdout=True, capture_stderr=True, quiet=True)
        )
        y, _ = sf.read(io.BytesIO(out), dtype="float32")
        return y
    except Exception:
        raise HTTPException(status_code=400, detail="Unsupported audio format")

# ================= HELPERS =================
def ensure_length(y):
    return np.pad(y, (0, max(0, TARGET_LEN - len(y))))[:TARGET_LEN]

def mel_from_wave(y):
    y = ensure_length(y)
    mel = librosa.feature.melspectrogram(
        y=y, sr=SR, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LEN
    )
    return librosa.power_to_db(mel, ref=np.max).astype(np.float32)

# ================= PDF GENERATOR =================
def generate_pdf_report(result: dict, filepath: str):
    c = canvas.Canvas(filepath, pagesize=A4)
    width, height = A4
    y = height - 2 * cm

    c.setFont("Helvetica-Bold", 20)
    c.drawCentredString(width / 2, y, "FLUENCY ASSIST – ANALYSIS REPORT")

    y -= 1.5 * cm
    c.setFont("Helvetica", 11)
    c.drawString(2 * cm, y, f"Email: {result['email']}")
    y -= 0.6 * cm
    c.drawString(2 * cm, y, f"File: {result['filename']}")
    y -= 0.6 * cm
    c.drawString(2 * cm, y, f"Date: {result['timestamp']}")

    y -= 1.2 * cm
    c.setFont("Helvetica-Bold", 14)
    c.drawString(2 * cm, y, "Result Summary")

    y -= 0.8 * cm
    c.setFont("Helvetica", 12)
    c.drawString(2 * cm, y, f"Status: {result['status']}")
    y -= 0.6 * cm
    c.drawString(2 * cm, y, f"Confidence: {result['confidence']}%")

    y -= 1 * cm
    c.setFont("Helvetica-Bold", 13)
    c.drawString(2 * cm, y, "Details")
    y -= 0.6 * cm
    c.setFont("Helvetica", 11)
    c.drawString(2 * cm, y, result["details"])

    y -= 1 * cm
    c.setFont("Helvetica-Bold", 13)
    c.drawString(2 * cm, y, "Speech Breakdown (%)")

    y -= 0.7 * cm
    c.setFont("Helvetica", 11)
    for k, v in result["breakdown"].items():
        c.drawString(2.5 * cm, y, f"{k.capitalize()}: {v}%")
        y -= 0.5 * cm

    c.setFont("Helvetica-Oblique", 9)
    c.drawCentredString(width / 2, 1.5 * cm, "Generated by Fluency Assist")
    c.showPage()
    c.save()

# ================= HEALTH =================
@app.get("/health")
def health():
    return {"status": "ok", "model_loaded": model is not None}

# ================= PREDICT =================
@app.post("/predict")
async def predict_audio(
    file: UploadFile = File(...),
    current_user: dict = Depends(get_current_user),
):
    raw = await file.read()
    y = audio_bytes_to_np(raw)
    mel = mel_from_wave(y)
    mel_tensor = torch.tensor(mel).unsqueeze(0).unsqueeze(0)

    if model is None:
        conf = random.uniform(55, 95)
        label = "Stuttering Detected" if conf > 70 else "Normal Speech"
    else:
        with torch.no_grad():
            probs = torch.softmax(model(mel_tensor), dim=1)
            conf = float(probs[0][1] * 100)
            label = "Stuttering Detected" if conf > 50 else "Normal Speech"

    breakdown = {"normal": 100, "repetition": 0, "prolongation": 0, "block": 0}
    details = "Speech appears normal."

    doc = {
        "email": current_user["email"],
        "filename": file.filename,
        "status": label,
        "confidence": round(conf, 2),
        "details": details,
        "breakdown": breakdown,
        "timestamp": datetime.utcnow(),
    }

    res = history_collection.insert_one(doc)
    doc["_id"] = str(res.inserted_id)
    doc["timestamp"] = doc["timestamp"].isoformat()

    return {"result": doc}

# ================= HISTORY =================
@app.get("/history")
def get_history(current_user: dict = Depends(get_current_user)):
    docs = list(
        history_collection.find({"email": current_user["email"]}).sort("timestamp", -1)
    )
    for d in docs:
        d["_id"] = str(d["_id"])
        d["timestamp"] = d["timestamp"].isoformat()
    return {"history": docs}

# ================= PDF DOWNLOAD =================
@app.get("/download-report/{report_id}")
def download_report(report_id: str, current_user: dict = Depends(get_current_user)):
    record = history_collection.find_one({
        "_id": ObjectId(report_id),
        "email": current_user["email"],
    })

    if not record:
        raise HTTPException(status_code=404, detail="Report not found")

    record["timestamp"] = record["timestamp"].isoformat()
    os.makedirs("reports", exist_ok=True)
    pdf_path = f"reports/fluency_report_{uuid.uuid4().hex}.pdf"

    generate_pdf_report(record, pdf_path)

    return FileResponse(
        pdf_path,
        media_type="application/pdf",
        filename="Fluency_Assist_Report.pdf",
    )

# ================= RUN =================
if __name__ == "__main__":
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
    )
